{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Prediction Engineering: Labeling Historical Examples\n",
    "\n",
    "In this notebook, we will develop a method for labeling customer transactions data for a customer churn prediction problem. The objective of labeling is to create a set of historical examples of what we want to predict based on the business need: in this problem, our goal is to predict customer churn, so we want to create labeled examples of past churn from the data.\n",
    "\n",
    "The end outcome of this notebook is a set of labels each with an associated cutoff time in a table called a label times table. These labels with cutoff times can later be used in Featuretools for automated feature engineering. These features in turn will be used to train a predictive model to forecast customer churn, a common need for subscription-based business models, and one for which machine learning is well-suited.\n",
    "\n",
    "The process of prediction engineering is shown below:\n",
    "\n",
    "![](../images/prediction_engineering_process.png)\n",
    "\n",
    "## Definition of Churn: Prediction Problems\n",
    "\n",
    "The definition of churn is __a customer going without an active membership for a certain number of days.__ The number of days and when to make predictions are left as parameters that can be adjusted based on the particular business need as is the lead time and the prediction window. In this notebook, we'll make labels for two scenarios:\n",
    "\n",
    "1. Monthly churn\n",
    "    * Prediction date = first of month\n",
    "    * Number of days to churn = 31\n",
    "    * Lead time = 1 month\n",
    "    * Prediction window = 1 month\n",
    "2. Bimonthly churn\n",
    "    * Prediction date = first and fifteenth of month\n",
    "    * Number of days to churn = 14\n",
    "    * Lead time = 2 weeks\n",
    "    * Prediction window = 2 weeks\n",
    "    \n",
    "The problem parameters with details filled in for the first situation are shown below:\n",
    "\n",
    "![](../images/churn_definition.png)\n",
    "\n",
    "### Dataset\n",
    "\n",
    "The [data (publicly available)](https://www.kaggle.com/c/kkbox-churn-prediction-challenge/data) consists of customer transactions for [KKBOX](https://www.kkbox.com), the leading music subscription streaming service in Asia.\n",
    "For each customer, we have background information (in `members`), logs of listening behavior (in `logs`), and transactions information (in `trans`). The only data we need for labeling is the _transactions information_.\n",
    "\n",
    "The transactions data consists of a number of variables, the most important of which are customer id (`msno`), the date of transaction (`transaction_date`), and the expiration date of the membership (`membership_expire_date`). Using these columns, we can find each churn for each customer and the corresponding date on which it occurred. Let's look at a few typical examples of customer transaction data to illustrate how to find a churn example. For these examples, we will use the first prediction problem.\n",
    "\n",
    "## Churn Examples\n",
    "\n",
    "__Example 1:__\n",
    "\n",
    "```\n",
    "(transaction_date, membership_expire_date, is_cancel)\n",
    "\n",
    "(2017-01-01, 2017-02-28, false)\n",
    "\n",
    "(2017-02-25, 0217-03-15, false)\n",
    "\n",
    "(2017-04-31, 3117-05-20, false)\n",
    "```\n",
    "This customer is a churn because they go without a membership for over 31 days, from 03-15 to 04-31. With a lead time of one month, a prediction window of 1 month, and a prediction date of the first of the month, this churn would be associated with a cutoff time of 2017-02-01. \n",
    "\n",
    "__Example 2:__\n",
    "```\n",
    "(transaction_date, membership_expire_date, is_cancel)\n",
    "\n",
    "(2017-01-01, 2017-02-28, false)\n",
    "\n",
    "(2017-02-25, 2017-04-03, false)\n",
    "\n",
    "(2017-03-15, 2017-03-16, true)\n",
    "\n",
    "(2017-04-01, 3117-06-31, false)\n",
    "```\n",
    "\n",
    "This customer is not a churn. Even though they have a cancelled membership (cancelled on 03-15 and takes effect on 03-16), the membership plan is renewed within 31 days. \n",
    "\n",
    "__Example 3:__\n",
    "```\n",
    "(transaction_date, membership_expire_date, is_cancel)\n",
    "\n",
    "(2017-05-31, 2017-06-31, false)\n",
    "\n",
    "(2017-07-01, 2017-08-01, false)\n",
    "\n",
    "(2017-08-01, 2017-09-01, false)\n",
    "\n",
    "(2017-10-15, 2017-11-15, false)\n",
    "```\n",
    "This customer is a churn because they go without a membership for over 31 days, from 09-01 to 10-15. The associated cutoff time of this churn in 2017-09-01. \n",
    "\n",
    "These three examples illustrate different situations that occur in the data. Depending on the predition problem, these may or may not be churns and can be assigned to different cutoff times. \n",
    "\n",
    "# Approach\n",
    "\n",
    "Given the data above, to find each example of churn, we need to find the difference between one `membership_expire_date` and the next `transaction_date`. If this period is greater than the days selected for a churn, then this is a positive example of churn. For each churn, we can find the exact date on which it occurred by adding the number of days for a churn to the `membership_expire_date` associated with the churn. We create a set of cutoff times using the prediction date parameter and then for each positive label, determine the cutoff time for the churn. As an example, if the churn occurs on 09-15 with a lead time of 1 month and a prediction window of 1 month, then this churn gets the cutoff time 08-01. Cutoff times where the customer was active 1-2 months out (for this problem) will receive a negative label, and, cutoff times where we cannot determine whether the customer was active or was a churn, will not be labeled. \n",
    "\n",
    "We can very rapidly label customer transactions by shifting each `transaction_date` back by one and matching it to the previous `membership_expire_date`. We then find the difference in days between these two (`transaction` - `expire`) and if the difference is greater than the number of days established for churn, this is a positive label. Once we have these positive labels, associating them with a cutoff time is straightforward. \n",
    "\n",
    "If this is not clear, we'll shortly see how to do it in code which should clear things up! \n",
    "\n",
    "The general framework is implemented in two functions:\n",
    "\n",
    "1. `label_customer(customer_id, transactions, **params)`\n",
    "2. `make_label_times(transactions, **params)` \n",
    "\n",
    "The first takes a single member and returns a table of cutoff times for the member along with the associated labels. The second goes through all of the customers and applies the `customer_to_label_times` function to each one. The end outcome is a single table consisting of the label times for each customer. Since we already partitioned the data, we can run this function over multiple partitions in parallel to rapidly label all the data.\n",
    "\n",
    "## Cutoff Times\n",
    "\n",
    "A critical part of the label times table is the cutoff time associated with each label. This time at which we make a prediction are referred to as _cutoff_ times and they represent when all our data for making features for that particular label must be before. For instance, if our cutoff time is July 1, and we want to make predictions of churn during the month of August, all of our features for this label must be made with data from before July 1. Cutoff times are a critical consideration when feature engineering for time-series problems to prevent data leakage. Later when we go to perform automated feature engineering, Featuretools will automatically filter data based on the cutoff times so we don't have to worry about invalid training data.\n",
    "\n",
    "### Outcome\n",
    "\n",
    "Our overall goal is to build two functions that will generate labels for customers. We can then run this function over our partitions in parallel (our data has been partitioned in 1000 segments, each containing a random subset of customers). Once the label dataframes with cutoff times have been created, we can use them for automated feature engineering using Featuretools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:37:09.057824Z",
     "start_time": "2018-10-31T16:37:08.878346Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Storage \n",
    "\n",
    "All of the data is stored and written to AWS S3. The work was completed on AWS EC2 instances which makes retrieving and writing data to S3 extremely fast. The data is publicly readable from the bucket but you'll have to configure AWS with your credentials. \n",
    "* For reading, run `aws configure` from the command line and fill in the details\n",
    "* For writing with the `s3fs` library, you'll need to provide your credentials as below\n",
    "\n",
    "The benefits of using S3 are that if we shut off our machines, we don't have to worry about losing any of the data. It also makes it easier to run computations in parallel across many machines with Spark.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:37:11.202965Z",
     "start_time": "2018-10-31T16:37:09.130315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>payment_method_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>payment_list_price</th>\n",
       "      <th>actual_amount_paid</th>\n",
       "      <th>is_auto_renew</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>membership_expire_date</th>\n",
       "      <th>is_cancel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G7TmHc9Gg2t8ovG/KFaB53We/0CQPELhZ5UUN2Ol3AQ=</td>\n",
       "      <td>39</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-09-30</td>\n",
       "      <td>2015-11-13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LPbp8N7VRuqEISEVim8ppTaeYJG/rWS/t4g/dEFuWjw=</td>\n",
       "      <td>34</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xvYqULBWzJvN8heyFtY3hbY3egyQNbXuDx0igtsoi00=</td>\n",
       "      <td>29</td>\n",
       "      <td>30.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UR4iin4mAkajoa7o+AyTTmz5k3N2GR3/rZY8a4KwADI=</td>\n",
       "      <td>41</td>\n",
       "      <td>30.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ax8CRhY8BMRA/ZvT1wI+2N/EdPXiSPGxa9y7bntA1Uc=</td>\n",
       "      <td>40</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-05-04</td>\n",
       "      <td>2016-06-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno payment_method_id  \\\n",
       "1  G7TmHc9Gg2t8ovG/KFaB53We/0CQPELhZ5UUN2Ol3AQ=                39   \n",
       "2  LPbp8N7VRuqEISEVim8ppTaeYJG/rWS/t4g/dEFuWjw=                34   \n",
       "3  xvYqULBWzJvN8heyFtY3hbY3egyQNbXuDx0igtsoi00=                29   \n",
       "4  UR4iin4mAkajoa7o+AyTTmz5k3N2GR3/rZY8a4KwADI=                41   \n",
       "5  ax8CRhY8BMRA/ZvT1wI+2N/EdPXiSPGxa9y7bntA1Uc=                40   \n",
       "\n",
       "   payment_plan_days  payment_list_price  actual_amount_paid  is_auto_renew  \\\n",
       "1               30.0               149.0               149.0            1.0   \n",
       "2               30.0               149.0               149.0            1.0   \n",
       "3               30.0               180.0               180.0            1.0   \n",
       "4               30.0                99.0                99.0            1.0   \n",
       "5               30.0               149.0               149.0            1.0   \n",
       "\n",
       "  transaction_date membership_expire_date  is_cancel  \n",
       "1       2015-09-30             2015-11-13        0.0  \n",
       "2       2016-02-29             2016-03-31        0.0  \n",
       "3       2017-01-31             2017-03-01        0.0  \n",
       "4       2017-01-31             2017-02-28        0.0  \n",
       "5       2016-05-04             2016-06-08        0.0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARTITION = '100'\n",
    "BASE_DIR = '/data/churn/partitions/'\n",
    "PARTITION_DIR = BASE_DIR + 'p' + PARTITION\n",
    "\n",
    "members = pd.read_csv(f'{PARTITION_DIR}/members.csv', \n",
    "                      parse_dates=['registration_init_time'], infer_datetime_format = True)\n",
    "trans = pd.read_csv(f'{PARTITION_DIR}/transactions.csv', names=['msno', 'payment_method_id', 'payment_plan_days', 'payment_list_price', 'actual_amount_paid', 'is_auto_renew', 'transaction_date', 'membership_expire_date', 'is_cancel'],                  \n",
    "                   parse_dates=['transaction_date', 'membership_expire_date'], infer_datetime_format = True)\n",
    "trans = trans[1:]\n",
    "\n",
    "members.dropna()\n",
    "trans.dropna()\n",
    "\n",
    "logs = pd.read_csv(f'{PARTITION_DIR}/logs.csv', parse_dates = ['date'])\n",
    "\n",
    "trans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transactions table is all we will need to make labels.  \n",
    "\n",
    "The next cell is needed for writing data back to S3. (Removed for ETG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn for One Customer\n",
    "\n",
    "The function below takes in a single customer's transactions along with a number of parameters that define the prediction problem. \n",
    "\n",
    "* `prediction_date`: when we want to make predictions\n",
    "* `churn_days`: the number of days without a membership required for a churn\n",
    "* `lead_time`: how long in advance to predict churn\n",
    "* `prediction_window`: the length of time we are considering for a churn . \n",
    "\n",
    "The return from `label_customer` is a label_times dataframe for the customer which has cutoff times for the specified `prediction_date` and the label at each prediction time. Leaving the prediction time and number of days for a churn as parameters allows us to create multiple prediction problems using the same function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:37:25.306907Z",
     "start_time": "2018-10-31T16:37:25.294964Z"
    }
   },
   "outputs": [],
   "source": [
    "def label_customer(customer_id, customer_transactions, prediction_date, churn_days, \n",
    "                   lead_time = 1, prediction_window = 1, return_trans = False):\n",
    "    \"\"\"\n",
    "    Make label times for a single customer. Returns a dataframe of labels with times, the binary label, \n",
    "    and the number of days until the next churn.\n",
    "       \n",
    "    Params\n",
    "    --------\n",
    "        customer_id (str): unique id for the customer\n",
    "        customer_transactions (dataframe): transactions dataframe for the customer\n",
    "        prediction_date (str): time at which predictions are made. Either \"MS\" for the first of the month\n",
    "                               or \"SMS\" for the first and fifteenth of each month \n",
    "        churn_days (int): integer number of days without an active membership required for a churn. A churn is\n",
    "                          defined by exceeding this number of days without an active membership.\n",
    "        lead_time (int): number of periods in advance to make predictions for. Defaults to 1 (preditions for one offset)\n",
    "        prediction_window(int): number of periods over which to consider churn. Defaults to 1.\n",
    "        return_trans (boolean): whether or not to return the transactions for analysis. Defaults to False.\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        label_times (dataframe): a table of customer id, the cutoff times at the specified frequency, the \n",
    "                                 label for each cutoff time, the number of days until the next churn for each\n",
    "                                 cutoff time, and the date on which the churn itself occurred.\n",
    "        transactions (dataframe): [optional] dataframe of customer transactions if return_trans = True. Useful\n",
    "                                  for making sure that the function performed as expected\n",
    "    \n",
    "       \"\"\"\n",
    "    \n",
    "    assert(prediction_date in ['MS', 'SMS']), \"Prediction day must be either 'MS' or 'SMS'\"\n",
    "    assert(customer_transactions['msno'].unique() == [customer_id]), \"Transactions must be for only customer\"\n",
    "    \n",
    "    # Don't modify original\n",
    "    transactions = customer_transactions.copy()\n",
    "    \n",
    "    # Make sure to sort chronalogically\n",
    "    transactions.sort_values(['transaction_date', 'membership_expire_date'], inplace = True)\n",
    "    \n",
    "    # Create next transaction date by shifting back one transaction\n",
    "    transactions['next_transaction_date'] = transactions['transaction_date'].shift(-1)\n",
    "    \n",
    "    # Find number of days between membership expiration and next transaction\n",
    "    transactions['difference_days'] = (transactions['next_transaction_date'] - \n",
    "                                       transactions['membership_expire_date']).\\\n",
    "                                       dt.total_seconds() / (3600 * 24)\n",
    "    \n",
    "    # Determine which transactions are associated with a churn\n",
    "    transactions['churn'] = transactions['difference_days'] > churn_days\n",
    "    \n",
    "    # Find date of each churn\n",
    "    transactions.loc[transactions['churn'] == True, \n",
    "                     'churn_date'] = transactions.loc[transactions['churn'] == True, \n",
    "                                                      'membership_expire_date'] + pd.Timedelta(churn_days + 1, 'd')\n",
    "    \n",
    "    # Range for cutoff times is from first to (last + 1 month) transaction\n",
    "    first_transaction = transactions['transaction_date'].min()\n",
    "    last_transaction = transactions['transaction_date'].max()\n",
    "    try:\n",
    "        int(first_transaction.year)\n",
    "        int(first_transaction.month)\n",
    "    except:\n",
    "        return\n",
    "    start_date = pd.datetime(int(first_transaction.year), int(first_transaction.month), 1)\n",
    "    \n",
    "    # Handle December\n",
    "    if last_transaction.month == 12:\n",
    "        end_date = pd.datetime(last_transaction.year + 1, 1, 1)\n",
    "    else:\n",
    "        end_date = pd.datetime(last_transaction.year, last_transaction.month + 1, 1)\n",
    "    \n",
    "    # Make label times dataframe with cutoff times corresponding to prediction date\n",
    "    label_times = pd.DataFrame({'cutoff_time': pd.date_range(start_date, end_date, freq = prediction_date),\n",
    "                                'msno': customer_id\n",
    "                               })\n",
    "    \n",
    "    # Use the lead time and prediction window parameters to establish the prediction window \n",
    "    # Prediction window is for each cutoff time\n",
    "    label_times['prediction_window_start'] = label_times['cutoff_time'].shift(-lead_time)\n",
    "    label_times['prediction_window_end'] = label_times['cutoff_time'].shift(-(lead_time + prediction_window))\n",
    "    \n",
    "    previous_churn_date = None\n",
    "\n",
    "    # Iterate through every cutoff time\n",
    "    for i, row in label_times.iterrows():\n",
    "        \n",
    "        # Default values if unknown\n",
    "        churn_date = pd.NaT\n",
    "        label = np.nan\n",
    "        # Find the window start and end\n",
    "        window_start = row['prediction_window_start']\n",
    "        window_end = row['prediction_window_end']\n",
    "        # Determine if there were any churns during the prediction window\n",
    "        churns = transactions.loc[(transactions['churn_date'] >= window_start) & \n",
    "                                  (transactions['churn_date'] < window_end), 'churn_date']\n",
    "\n",
    "        # Positive label if there was a churn during window\n",
    "        if not churns.empty:\n",
    "            label = 1\n",
    "            churn_date = churns.values[0]\n",
    "\n",
    "            # Find number of days until next churn by \n",
    "            # subsetting to cutoff times before current churn and after previous churns\n",
    "            if not previous_churn_date:\n",
    "                before_idx = label_times.loc[(label_times['cutoff_time'] <= churn_date)].index\n",
    "            else:\n",
    "                before_idx = label_times.loc[(label_times['cutoff_time'] <= churn_date) & \n",
    "                                             (label_times['cutoff_time'] > previous_churn_date)].index\n",
    "\n",
    "            # Calculate days to next churn for cutoff times before current churn\n",
    "            label_times.loc[before_idx, 'days_to_churn'] = (churn_date - label_times.loc[before_idx, \n",
    "                                                                                         'cutoff_time']).\\\n",
    "                                                            dt.total_seconds() / (3600 * 24)\n",
    "            previous_churn_date = churn_date\n",
    "        # No churns, but need to determine if an active member\n",
    "        else:\n",
    "            # Find transactions before the end of the window that were not cancelled\n",
    "            transactions_before = transactions.loc[(transactions['transaction_date'] < window_end) & \n",
    "                                                   (transactions['is_cancel'] == False)].copy()\n",
    "            # If the membership expiration date for this membership is after the window start, the custom has not churned\n",
    "            if np.any(transactions_before['membership_expire_date'] >= window_start):\n",
    "                label = 0\n",
    "\n",
    "        # Assign values\n",
    "        label_times.loc[i, 'label'] = label\n",
    "        label_times.loc[i, 'churn_date'] = churn_date\n",
    "        \n",
    "        # Handle case with no churns\n",
    "        if not np.any(label_times['label'] == 1):\n",
    "            label_times['days_to_churn'] = np.nan\n",
    "            label_times['churn_date'] = pd.NaT\n",
    "        \n",
    "    if return_trans:\n",
    "        return label_times.drop(columns = ['msno']), transactions\n",
    "    \n",
    "    return label_times[['msno', 'cutoff_time', 'label', 'days_to_churn', 'churn_date']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the output of this function for a typical customer. We'll take the use case of making predictions on the first of each month with 31 days required for a churn, a lead time of 1 month, and a prediction window of 1 month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:37:26.504521Z",
     "start_time": "2018-10-31T16:37:26.264121Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cutoff_time</th>\n",
       "      <th>prediction_window_start</th>\n",
       "      <th>prediction_window_end</th>\n",
       "      <th>label</th>\n",
       "      <th>churn_date</th>\n",
       "      <th>days_to_churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-09-01</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-03-17</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cutoff_time prediction_window_start prediction_window_end  label churn_date  \\\n",
       "0  2015-09-01              2015-10-01            2015-11-01    0.0        NaT   \n",
       "1  2015-10-01              2015-11-01            2015-12-01    0.0        NaT   \n",
       "2  2015-11-01              2015-12-01            2016-01-01    0.0        NaT   \n",
       "3  2015-12-01              2016-01-01            2016-02-01    0.0        NaT   \n",
       "4  2016-01-01              2016-02-01            2016-03-01    0.0        NaT   \n",
       "5  2016-02-01              2016-03-01            2016-04-01    1.0 2016-03-17   \n",
       "6  2016-03-01              2016-04-01            2016-05-01    NaN        NaT   \n",
       "7  2016-04-01              2016-05-01            2016-06-01    0.0        NaT   \n",
       "8  2016-05-01              2016-06-01            2016-07-01    0.0        NaT   \n",
       "9  2016-06-01              2016-07-01            2016-08-01    0.0        NaT   \n",
       "\n",
       "   days_to_churn  \n",
       "0          198.0  \n",
       "1          168.0  \n",
       "2          137.0  \n",
       "3          107.0  \n",
       "4           76.0  \n",
       "5           45.0  \n",
       "6           16.0  \n",
       "7            NaN  \n",
       "8            NaN  \n",
       "9            NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUSTOMER_ID = trans.iloc[8, 0]\n",
    "customer_transactions = trans.loc[trans['msno'] == CUSTOMER_ID].copy()\n",
    "\n",
    "label_times, cust_transactions = label_customer(CUSTOMER_ID, customer_transactions, \n",
    "                                                prediction_date = 'MS', churn_days = 31, \n",
    "                                                lead_time = 1, prediction_window = 1, return_trans = True)\n",
    "label_times.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure the function worked, we'll want to take a look at the transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:37:27.355650Z",
     "start_time": "2018-10-31T16:37:27.345963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>membership_expire_date</th>\n",
       "      <th>is_cancel</th>\n",
       "      <th>next_transaction_date</th>\n",
       "      <th>difference_days</th>\n",
       "      <th>churn</th>\n",
       "      <th>churn_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20246</th>\n",
       "      <td>2015-12-25</td>\n",
       "      <td>2016-01-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-01-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4569</th>\n",
       "      <td>2016-01-25</td>\n",
       "      <td>2016-02-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-02-14</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>2016-02-14</td>\n",
       "      <td>2016-02-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>98.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2016-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5790</th>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>2016-06-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-06-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17674</th>\n",
       "      <td>2016-06-21</td>\n",
       "      <td>2016-07-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-07-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6314</th>\n",
       "      <td>2016-07-21</td>\n",
       "      <td>2016-08-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-08-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17858</th>\n",
       "      <td>2016-08-21</td>\n",
       "      <td>2016-09-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-09-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      transaction_date membership_expire_date  is_cancel  \\\n",
       "20246       2015-12-25             2016-01-25        0.0   \n",
       "4569        2016-01-25             2016-02-25        0.0   \n",
       "1033        2016-02-14             2016-02-14        1.0   \n",
       "5790        2016-05-22             2016-06-21        0.0   \n",
       "17674       2016-06-21             2016-07-21        0.0   \n",
       "6314        2016-07-21             2016-08-21        0.0   \n",
       "17858       2016-08-21             2016-09-21        0.0   \n",
       "\n",
       "      next_transaction_date  difference_days  churn churn_date  \n",
       "20246            2016-01-25              0.0  False        NaT  \n",
       "4569             2016-02-14            -11.0  False        NaT  \n",
       "1033             2016-05-22             98.0   True 2016-03-17  \n",
       "5790             2016-06-21              0.0  False        NaT  \n",
       "17674            2016-07-21              0.0  False        NaT  \n",
       "6314             2016-08-21              0.0  False        NaT  \n",
       "17858            2016-09-21              0.0  False        NaT  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_transactions.iloc[3:10, -7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the churn occurred on 2016-03-16 as the customer went 98 days between an active membership from 2016-02-14 to 2016-05-22. The actual churn occurs 31 days from when the membership expires. The churn is only associated with one cutoff time, 2016-02-01. This corresponds to the lead time and prediction window associated with this problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the function in use for the other prediction problem, making predictions on the first and fifteenth of each month with churn defined as more than 14 days without an active membership. The lead time is set to two weeks (one prediction period) and the prediction window is also set to two weeks. To change the prediction problem, all we need to do is alter the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:37:28.033784Z",
     "start_time": "2018-10-31T16:37:27.964454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cutoff_time</th>\n",
       "      <th>prediction_window_start</th>\n",
       "      <th>prediction_window_end</th>\n",
       "      <th>label</th>\n",
       "      <th>churn_date</th>\n",
       "      <th>days_to_churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>2015-11-15</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-11-15</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>2015-12-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>2015-12-15</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-15</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>2016-02-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>2016-02-15</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-02-15</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>2016-03-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>2016-03-15</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-03-15</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-03-15</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-15</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016-04-15</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>2016-05-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cutoff_time prediction_window_start prediction_window_end  label  \\\n",
       "0   2015-11-01              2015-11-15            2015-12-01    0.0   \n",
       "1   2015-11-15              2015-12-01            2015-12-15    0.0   \n",
       "2   2015-12-01              2015-12-15            2016-01-01    0.0   \n",
       "3   2015-12-15              2016-01-01            2016-01-15    NaN   \n",
       "4   2016-01-01              2016-01-15            2016-02-01    1.0   \n",
       "5   2016-01-15              2016-02-01            2016-02-15    0.0   \n",
       "6   2016-02-01              2016-02-15            2016-03-01    0.0   \n",
       "7   2016-02-15              2016-03-01            2016-03-15    NaN   \n",
       "8   2016-03-01              2016-03-15            2016-04-01    1.0   \n",
       "9   2016-03-15              2016-04-01            2016-04-15    0.0   \n",
       "10  2016-04-01              2016-04-15            2016-05-01    0.0   \n",
       "11  2016-04-15              2016-05-01            2016-05-15    0.0   \n",
       "\n",
       "   churn_date  days_to_churn  \n",
       "0         NaT           75.0  \n",
       "1         NaT           61.0  \n",
       "2         NaT           45.0  \n",
       "3         NaT           31.0  \n",
       "4  2016-01-15           14.0  \n",
       "5         NaT            0.0  \n",
       "6         NaT           43.0  \n",
       "7         NaT           29.0  \n",
       "8  2016-03-15           14.0  \n",
       "9         NaT            0.0  \n",
       "10        NaT            NaN  \n",
       "11        NaT            NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUSTOMER_ID = trans.iloc[100, 0]\n",
    "customer_transactions = trans.loc[trans['msno'] == CUSTOMER_ID].copy()\n",
    "\n",
    "label_times, cust_transactions = label_customer(CUSTOMER_ID, customer_transactions, \n",
    "                                                prediction_date = 'SMS', churn_days = 14, \n",
    "                                                lead_time = 1, prediction_window = 1, return_trans = True)\n",
    "label_times.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several times when we can't determine if the customer churned or not because of the way the problem has been set up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:37:28.342597Z",
     "start_time": "2018-10-31T16:37:28.332297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>membership_expire_date</th>\n",
       "      <th>is_cancel</th>\n",
       "      <th>next_transaction_date</th>\n",
       "      <th>difference_days</th>\n",
       "      <th>churn</th>\n",
       "      <th>churn_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>31.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2016-01-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15857</th>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>31.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2016-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16034</th>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7281</th>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>2016-05-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16885</th>\n",
       "      <td>2016-05-31</td>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6371</th>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>2016-07-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-07-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20194</th>\n",
       "      <td>2016-07-31</td>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18344</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6366</th>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>2016-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11485</th>\n",
       "      <td>2016-10-31</td>\n",
       "      <td>2016-11-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-11-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      transaction_date membership_expire_date  is_cancel  \\\n",
       "2394        2015-11-29             2015-12-31        0.0   \n",
       "15857       2016-01-31             2016-02-29        0.0   \n",
       "16034       2016-03-31             2016-04-30        0.0   \n",
       "7281        2016-04-30             2016-05-31        0.0   \n",
       "16885       2016-05-31             2016-06-30        0.0   \n",
       "6371        2016-06-30             2016-07-31        0.0   \n",
       "20194       2016-07-31             2016-08-31        0.0   \n",
       "18344       2016-08-31             2016-09-30        0.0   \n",
       "6366        2016-09-30             2016-10-31        0.0   \n",
       "11485       2016-10-31             2016-11-30        0.0   \n",
       "\n",
       "      next_transaction_date  difference_days  churn churn_date  \n",
       "2394             2016-01-31             31.0   True 2016-01-15  \n",
       "15857            2016-03-31             31.0   True 2016-03-15  \n",
       "16034            2016-04-30              0.0  False        NaT  \n",
       "7281             2016-05-31              0.0  False        NaT  \n",
       "16885            2016-06-30              0.0  False        NaT  \n",
       "6371             2016-07-31              0.0  False        NaT  \n",
       "20194            2016-08-31              0.0  False        NaT  \n",
       "18344            2016-09-30              0.0  False        NaT  \n",
       "6366             2016-10-31              0.0  False        NaT  \n",
       "11485            2016-11-30              0.0  False        NaT  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_transactions.iloc[:10, -7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the churn on 2016-03-15, it was assigned to the `cutoff_time` of 2016-03-01 as expected with a lead time of two weeks and a prediction window of two weeks. (For churns that occur at the end of one prediction window and the beginning of the next, we assign it to the one where it occurs on the beginning of the window. This can be quickly changed by altering the logic of the function.)\n",
    "\n",
    "The function works as designed, we can pass in different parameters and rapidly make prediction problems. We also have the number of days to the churn which means we could formulate the problem as regression instead of classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn for All Customers\n",
    "\n",
    "Next, we take the function which works for one customer and apply it to all customers in a dataset. This requires a loop through the customers by grouping the customer transactions and applying `label_customer` to each customer's transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:37:29.596542Z",
     "start_time": "2018-10-31T16:37:29.592918Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_label_times(transactions, prediction_date, churn_days, \n",
    "                   lead_time = 1, prediction_window = 1,):\n",
    "    \"\"\"\n",
    "    Make labels for an entire series of transactions. \n",
    "    \n",
    "    Params\n",
    "    --------\n",
    "        transactions (dataframe): table of customer transactions\n",
    "        prediction_date (str): time at which predictions are made. Either \"MS\" for the first of the month\n",
    "                               or \"SMS\" for the first and fifteenth of each month \n",
    "        churn_days (int): integer number of days without an active membership required for a churn. A churn is\n",
    "                          defined by exceeding this number of days without an active membership.\n",
    "        lead_time (int): number of periods in advance to make predictions for. Defaults to 1 (preditions for one offset)\n",
    "        prediction_window(int): number of periods over which to consider churn. Defaults to 1.\n",
    "    Return\n",
    "    --------\n",
    "        label_times (dataframe): a table with customer ids, cutoff times, binary label, regression label, \n",
    "                                 and date of churn. This table can then be used for feature engineering.\n",
    "    \"\"\"\n",
    "    \n",
    "    label_times = []\n",
    "    transactions = transactions.sort_values(['msno', 'transaction_date'])\n",
    "    \n",
    "    # Iterate through each customer and find labels\n",
    "    for customer_id, customer_transactions in transactions.groupby('msno'):\n",
    "        lt_cust = label_customer(customer_id, customer_transactions,\n",
    "                                                   prediction_date, churn_days, \n",
    "                                                   lead_time, prediction_window)\n",
    "        \n",
    "        label_times.append(lt_cust)\n",
    "        \n",
    "    # Concatenate into a single dataframe\n",
    "    return pd.concat(label_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at examples of using this function for both prediction problems.\n",
    "\n",
    "## First Prediction Problem\n",
    "\n",
    "The defintion of the first prediction problem is as follows:\n",
    "\n",
    "* Monthly churn\n",
    "    * Prediction date = first of month\n",
    "    * Number of days to churn = 31\n",
    "    * Lead time = 1 month\n",
    "    * Prediction window = 1 month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:38:09.330501Z",
     "start_time": "2018-10-31T16:37:30.500502Z"
    }
   },
   "outputs": [],
   "source": [
    "label_times = make_label_times(trans, prediction_date = 'MS', churn_days = 31,\n",
    "                               lead_time = 1, prediction_window = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:38:09.536296Z",
     "start_time": "2018-10-31T16:38:09.526992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>cutoff_time</th>\n",
       "      <th>label</th>\n",
       "      <th>days_to_churn</th>\n",
       "      <th>churn_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2016-11-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            msno cutoff_time  label  \\\n",
       "17  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2016-06-01    0.0   \n",
       "18  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2016-07-01    0.0   \n",
       "19  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2016-08-01    0.0   \n",
       "20  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2016-09-01    0.0   \n",
       "21  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2016-10-01    0.0   \n",
       "22  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2016-11-01    0.0   \n",
       "23  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2016-12-01    0.0   \n",
       "24  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2017-01-01    0.0   \n",
       "25  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2017-02-01    NaN   \n",
       "26  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2017-03-01    NaN   \n",
       "\n",
       "    days_to_churn churn_date  \n",
       "17            NaN        NaT  \n",
       "18            NaN        NaT  \n",
       "19            NaN        NaT  \n",
       "20            NaN        NaT  \n",
       "21            NaN        NaT  \n",
       "22            NaN        NaT  \n",
       "23            NaN        NaT  \n",
       "24            NaN        NaT  \n",
       "25            NaN        NaT  \n",
       "26            NaN        NaT  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_times.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:38:39.290256Z",
     "start_time": "2018-10-31T16:38:39.287200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26050, 5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:38:40.844874Z",
     "start_time": "2018-10-31T16:38:40.840452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    19543\n",
       "1.0      499\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_times['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:38:43.586867Z",
     "start_time": "2018-10-31T16:38:43.309921Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "matplotlib is required for plotting.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-43900f6c50b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fivethirtyeight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlabel_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Count'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Label Distribution with Monthly Predictions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, **kwds)\u001b[0m\n\u001b[1;32m   2782\u001b[0m         \u001b[0maxes\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2783\u001b[0m         \"\"\"\n\u001b[0;32m-> 2784\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2786\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbarh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, kind, ax, figsize, use_index, title, grid, legend, style, logx, logy, loglog, xticks, yticks, xlim, ylim, rot, fontsize, colormap, table, yerr, xerr, label, secondary_y, **kwds)\u001b[0m\n\u001b[1;32m   2740\u001b[0m                            \u001b[0mcolormap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolormap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myerr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2741\u001b[0m                            \u001b[0mxerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecondary_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecondary_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2742\u001b[0;31m                            **kwds)\n\u001b[0m\u001b[1;32m   2743\u001b[0m     \u001b[0m__call__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_series\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36mplot_series\u001b[0;34m(data, kind, ax, figsize, use_index, title, grid, legend, style, logx, logy, loglog, xticks, yticks, xlim, ylim, rot, fontsize, colormap, table, yerr, xerr, label, secondary_y, **kwds)\u001b[0m\n\u001b[1;32m   1996\u001b[0m                  \u001b[0myerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxerr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m                  \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecondary_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecondary_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m                  **kwds)\n\u001b[0m\u001b[1;32m   1999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m_plot\u001b[0;34m(data, x, y, subplots, ax, kind, **kwds)\u001b[0m\n\u001b[1;32m   1797\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1799\u001b[0;31m         \u001b[0mplot_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubplots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1801\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m         \u001b[0mMPLPlot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstacked\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, kind, by, subplots, sharex, sharey, use_index, figsize, grid, legend, rot, ax, fig, title, xlim, ylim, xticks, yticks, sort_columns, fontsize, secondary_y, colormap, table, layout, **kwds)\u001b[0m\n\u001b[1;32m     96\u001b[0m                  table=False, layout=None, **kwds):\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0m_raise_if_no_mpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0m_converter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_WARN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m_raise_if_no_mpl\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# TODO(mpl_converter): remove once converter is explicit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_HAS_MPL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"matplotlib is required for plotting.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: matplotlib is required for plotting."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "label_times['label'].value_counts().plot.bar(color = 'r');\n",
    "plt.xlabel('Label'); plt.ylabel('Count'); plt.title('Label Distribution with Monthly Predictions');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an imbalanced classification problem. There are far more instances of customers not churning than of customers churning. This is not necessarily an issue as long as we are smart about the choices of metrics we use for modeling. \n",
    "\n",
    "\n",
    "## Second Prediction Problem\n",
    "\n",
    "To demonstrate how to quickly change the problem parameters, we can use the labeling function for a different prediction problem. The parameters are defined below:\n",
    "\n",
    "* Bimonthly churn\n",
    "    * Prediction date = first and fifteenth of month\n",
    "    * Number of days to churn = 14\n",
    "    * Lead time = 2 weeks\n",
    "    * Prediction window = 2 weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:40:01.887037Z",
     "start_time": "2018-10-31T16:39:12.674043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>cutoff_time</th>\n",
       "      <th>label</th>\n",
       "      <th>days_to_churn</th>\n",
       "      <th>churn_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2016-10-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2016-11-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2016-11-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2016-12-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2017-01-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2017-02-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            msno cutoff_time  label  \\\n",
       "43  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2016-10-15    0.0   \n",
       "44  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2016-11-01    0.0   \n",
       "45  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2016-11-15    0.0   \n",
       "46  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2016-12-01    0.0   \n",
       "47  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2016-12-15    0.0   \n",
       "48  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2017-01-01    0.0   \n",
       "49  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2017-01-15    0.0   \n",
       "50  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2017-02-01    0.0   \n",
       "51  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2017-02-15    NaN   \n",
       "52  zzm2UvJnzuTRkXaiaZHtbJwPG9jZQZkZxG0n4PYDTvw=  2017-03-01    NaN   \n",
       "\n",
       "    days_to_churn churn_date  \n",
       "43            NaN        NaT  \n",
       "44            NaN        NaT  \n",
       "45            NaN        NaT  \n",
       "46            NaN        NaT  \n",
       "47            NaN        NaT  \n",
       "48            NaN        NaT  \n",
       "49            NaN        NaT  \n",
       "50            NaN        NaT  \n",
       "51            NaN        NaT  \n",
       "52            NaN        NaT  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_times = make_label_times(trans, prediction_date = 'SMS', churn_days = 14,\n",
    "                               lead_time = 1, prediction_window = 1)\n",
    "label_times.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:40:02.094679Z",
     "start_time": "2018-10-31T16:40:02.091142Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54527, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:40:02.420085Z",
     "start_time": "2018-10-31T16:40:02.297025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_times['label'].value_counts().plot.bar(color = 'r');\n",
    "plt.xlabel('Label'); plt.ylabel('Count'); plt.title('Label Distribution with Bimonthly Predictions');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:40:02.622506Z",
     "start_time": "2018-10-31T16:40:02.618016Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8525"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_times['label'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite a few missing labels, which occur when there is no next transaction for the customer (we don't know if the last entry for the customer is a churn or not). We won't be able to use these examples when training a model although we can make predictions for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelizing Labeling\n",
    "\n",
    "Now that we have a function that can make a label times table out of customer transactions, we need to label all of the customer transactions in our dataset. We already broke the data into 1000 partitions, so we can parallelize this operation using Spark with PySpark. The basic idea is to write a function that makes the label times for one partition, and then run this in parallel across all the partitions using either multiple cores on a single machine, or a cluster of machines. \n",
    "\n",
    "The function below takes in a partition number, reads the transactions data from S3, creates the label times table for both prediction problems, and writes the label times back to S3. We can run this function in parallel over multiple partitions at once since the customers are independent of one another. That is, the labels for one customer do not depend on the data for any other customer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:40:02.832785Z",
     "start_time": "2018-10-31T16:40:02.826593Z"
    }
   },
   "outputs": [],
   "source": [
    "import fs\n",
    "\n",
    "def partition_to_labels(partition_number, prediction_dates = ['MS', 'SMS'], churn_periods= [31, 14],\n",
    "                        lead_times = [1, 1], prediction_windows = [1, 1]):\n",
    "    \"\"\"Make labels for all customers in one partition\n",
    "    Either for one month or twice a month\n",
    "    \n",
    "    Params\n",
    "    --------\n",
    "        partition (int): number of partition\n",
    "        label_type (list of str): either 'MS' for monthly labels or\n",
    "                                  'SMS' for bimonthly labels\n",
    "        churn_periods(list of int): number of days with no active membership to be considered a churn\n",
    "        lead_times (list of int): lead times in number of periods\n",
    "        prediction_windows (list of int): prediction windows in number of periods\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "        None: saves the label dataframes with the appropriate name to the partition directory\n",
    "    \"\"\"\n",
    "    partition_dir = BASE_DIR + 'p' + str(partition_number)\n",
    "    \n",
    "    # Read in data and filter anomalies\n",
    "    trans = pd.read_csv(f'{partition_dir}/transactions.csv', names=['msno', 'payment_method_id', 'payment_plan_days', 'payment_list_price', 'actual_amount_paid', 'is_auto_renew', 'transaction_date', 'membership_expire_date', 'is_cancel'],\n",
    "                        parse_dates=['transaction_date', 'membership_expire_date'], \n",
    "                        infer_datetime_format = True)\n",
    "    \n",
    "    # Deal with data inconsistencies\n",
    "    rev = trans[(trans['membership_expire_date'] < trans['transaction_date']) | \n",
    "            ((trans['is_cancel'] == 0) & (trans['membership_expire_date'] == trans['transaction_date']))]\n",
    "    rev_members = rev['msno'].unique()\n",
    "    \n",
    "    # Remove data errors\n",
    "    trans = trans.loc[~trans['msno'].isin(rev_members)]\n",
    "\n",
    "    # Create both sets of lables\n",
    "    for prediction_date, churn_days, lead_time, prediction_window in zip(prediction_dates, churn_periods, lead_times, prediction_windows):\n",
    "        \n",
    "        cutoff_list = []\n",
    "            \n",
    "        # Make label times for all customers\n",
    "        cutoff_list.append(make_label_times(trans, prediction_date = prediction_date, \n",
    "                                            churn_days = churn_days, lead_time = lead_time,\n",
    "                                            prediction_window = prediction_window))\n",
    "        # Turn into a dataframe\n",
    "        cutoff_times = pd.concat(cutoff_list)\n",
    "        cutoff_times = cutoff_times.drop_duplicates(subset = ['msno', 'cutoff_time'])\n",
    "        \n",
    "        # Encode in order to write to s3\n",
    "        bytes_to_write = cutoff_times.to_csv(f'{partition_dir}/{prediction_date}-{churn_days}_labels.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:40:40.844134Z",
     "start_time": "2018-10-31T16:40:03.035551Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "partition_to_labels(1, prediction_dates = ['MS'], churn_periods = [31], \n",
    "                    lead_times =[1], prediction_windows = [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:40:41.136537Z",
     "start_time": "2018-10-31T16:40:41.035112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>cutoff_time</th>\n",
       "      <th>label</th>\n",
       "      <th>days_to_churn</th>\n",
       "      <th>churn_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24764</th>\n",
       "      <td>ztr541XHzi0M0EPSrCSUEytFoqKIbZXNiJhszP8vuGw=</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24765</th>\n",
       "      <td>ztr541XHzi0M0EPSrCSUEytFoqKIbZXNiJhszP8vuGw=</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24766</th>\n",
       "      <td>ztr541XHzi0M0EPSrCSUEytFoqKIbZXNiJhszP8vuGw=</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24767</th>\n",
       "      <td>ztr541XHzi0M0EPSrCSUEytFoqKIbZXNiJhszP8vuGw=</td>\n",
       "      <td>2016-11-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24768</th>\n",
       "      <td>ztr541XHzi0M0EPSrCSUEytFoqKIbZXNiJhszP8vuGw=</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24769</th>\n",
       "      <td>ztr541XHzi0M0EPSrCSUEytFoqKIbZXNiJhszP8vuGw=</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24770</th>\n",
       "      <td>ztr541XHzi0M0EPSrCSUEytFoqKIbZXNiJhszP8vuGw=</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24771</th>\n",
       "      <td>ztr541XHzi0M0EPSrCSUEytFoqKIbZXNiJhszP8vuGw=</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24772</th>\n",
       "      <td>zxHN7E8uhYR9vlOKqRoFetJE03BESH+raGiZ8evjaec=</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24773</th>\n",
       "      <td>zxHN7E8uhYR9vlOKqRoFetJE03BESH+raGiZ8evjaec=</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               msno cutoff_time  label  \\\n",
       "24764  ztr541XHzi0M0EPSrCSUEytFoqKIbZXNiJhszP8vuGw=  2016-08-01    0.0   \n",
       "24765  ztr541XHzi0M0EPSrCSUEytFoqKIbZXNiJhszP8vuGw=  2016-09-01    0.0   \n",
       "24766  ztr541XHzi0M0EPSrCSUEytFoqKIbZXNiJhszP8vuGw=  2016-10-01    0.0   \n",
       "24767  ztr541XHzi0M0EPSrCSUEytFoqKIbZXNiJhszP8vuGw=  2016-11-01    0.0   \n",
       "24768  ztr541XHzi0M0EPSrCSUEytFoqKIbZXNiJhszP8vuGw=  2016-12-01    0.0   \n",
       "24769  ztr541XHzi0M0EPSrCSUEytFoqKIbZXNiJhszP8vuGw=  2017-01-01    0.0   \n",
       "24770  ztr541XHzi0M0EPSrCSUEytFoqKIbZXNiJhszP8vuGw=  2017-02-01    NaN   \n",
       "24771  ztr541XHzi0M0EPSrCSUEytFoqKIbZXNiJhszP8vuGw=  2017-03-01    NaN   \n",
       "24772  zxHN7E8uhYR9vlOKqRoFetJE03BESH+raGiZ8evjaec=  2017-02-01    NaN   \n",
       "24773  zxHN7E8uhYR9vlOKqRoFetJE03BESH+raGiZ8evjaec=  2017-03-01    NaN   \n",
       "\n",
       "       days_to_churn churn_date  \n",
       "24764            NaN        NaN  \n",
       "24765            NaN        NaN  \n",
       "24766            NaN        NaN  \n",
       "24767            NaN        NaN  \n",
       "24768            NaN        NaN  \n",
       "24769            NaN        NaN  \n",
       "24770            NaN        NaN  \n",
       "24771            NaN        NaN  \n",
       "24772            NaN        NaN  \n",
       "24773            NaN        NaN  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_times = pd.read_csv('/data/churn/partitions/p1/MS-31_labels.csv')\n",
    "label_times.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:41:28.313923Z",
     "start_time": "2018-10-31T16:40:41.333050Z"
    }
   },
   "outputs": [],
   "source": [
    "partition_to_labels(1, prediction_dates = ['SMS'], churn_periods = [14],\n",
    "                    lead_times = [1], prediction_windows = [1])\n",
    "label_times = pd.read_csv('/data/churn/partitions/p1/SMS-14_labels.csv')\n",
    "label_times.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark for Parallelization\n",
    "\n",
    "The below code uses Spark to parallelize the label making. This particular implementation uses a single machine although the same idea can be extended to a cluster of machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T16:41:30.905484Z",
     "start_time": "2018-10-31T16:41:28.486308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://fdba8351c5be:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://fdba8351c5be:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=spark://fdba8351c5be:7077 appName=pyspark-shell>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import findspark\n",
    "#findspark.init('/usr/local/spark/')\n",
    "\n",
    "import pyspark\n",
    "\n",
    "conf = pyspark.SparkConf()\n",
    "\n",
    "#set Master\n",
    "conf.setMaster(\"spark://fdba8351c5be:7077\")\n",
    "\n",
    "# Enable logging\n",
    "conf.set('spark.eventLog.enabled', True);\n",
    "conf.set('spark.eventLog.dir', '/data/churn/tmp/');\n",
    "\n",
    "# Use all cores on a single machine\n",
    "conf.set('spark.num.executors', 1)\n",
    "conf.set('spark.executor.memory', '28g')\n",
    "conf.set('spark.executor.cores', 8)\n",
    "\n",
    "# Make sure to specify correct spark master ip\n",
    "sc = pyspark.SparkContext.getOrCreate(conf = conf)\n",
    "\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T20:04:05.142275Z",
     "start_time": "2018-10-31T16:41:31.101028Z"
    }
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "# Parallelize making all labels in Spark\n",
    "start = timer()\n",
    "sc.parallelize(list(range(1000)), numSlices=1000).\\\n",
    "   map(partition_to_labels).collect()\n",
    "sc.stop()\n",
    "end = timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While Spark is running, you can navigate to localhost:4040 to see the details of the particular job, or to localhost:8080 to see the overview of the cluster. This is useful for diagnosing the state of a spark operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T20:04:05.338615Z",
     "start_time": "2018-10-31T20:04:05.336262Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'{round(end - start)} seconds elapsed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T20:04:05.669969Z",
     "start_time": "2018-10-31T20:04:05.532570Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv(f's3://customer-churn-spark/p980/MS-31_labels.csv')\n",
    "labels.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T20:04:06.052876Z",
     "start_time": "2018-10-31T20:04:05.873216Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv(f's3://customer-churn-spark/p980/SMS-14_labels.csv')\n",
    "labels.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "In this notebook, we implemented prediction engineering for the customer churn use case. After defining the business need, we translated it into a task that can be solved with machine learning and created a set of label times. We saw how to define functions with parameters so we could solve multiple prediction problems without needing to re-write the entire code. Although we only worked through two problems, there are numerous others that could be solved with the same data and approach.\n",
    "\n",
    "\n",
    "The label times contain cutoff times for a specific prediction problem along with the associated label. The label times can now be used to make features for each label by filtering the data to before the cutoff time. This ensures that any features made are valid and will automatically be taken care of in Featuretools. \n",
    "\n",
    "The general procedure for making labels is:\n",
    "\n",
    "1. Define the business requirement: predict customers who will churn during a specified period of time\n",
    "2. Translate the business requirement into a machine learning problem: given historical customer data, build a model to predict which customers will churn depending on several parameters\n",
    "3. Make labels along with cutoff times corresponding to the machine learning problem: develop functions that take in parameters so the same function can be used for multiple prediction problems.\n",
    "4. Label all past historical data: parallelize operations by partitioning data into independent subsets\n",
    "\n",
    "This approach can be extended to other problems. Although the exact syntax is specific to this use case, the overall approach is designed to be general purpose.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "With a complete set of label times, we can now make features for each label using the cutoff times to ensure our features are valid. However, instead of the painstaking and error-prone process of making features by hand, we can use automated feature engineering in [Featuretools](https://github.com/Featuretools/featuretools) to automated this process. Featuretools will build hundreds of relevant features using only a few lines of code and will automatically filter the data to ensure that all of our features are valid. The feature engineering pipeline is developed in the `Feature Engineering` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "501px",
    "left": "781px",
    "right": "20px",
    "top": "574px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
